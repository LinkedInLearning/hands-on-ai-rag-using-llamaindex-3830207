{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install llama-index==0.10.37 llama-index-embeddings-openai==0.1.9 qdrant-client==1.9.1 llama-index-vector-stores-qdrant==0.2.8 llama-index-llms-openai==0.1.19 llama-index-retrievers-bm25"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note, you will need to run the following:\n",
    "\n",
    "`pip install llama-index-retrievers-bm25`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from getpass import getpass\n",
    "import nest_asyncio\n",
    "\n",
    "from IPython.display import Markdown, display\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "nest_asyncio.apply()\n",
    "\n",
    "load_dotenv(\"\")\n",
    "\n",
    "sys.path.append('../helpers')\n",
    "\n",
    "from utils import setup_llm, setup_embed_model, setup_vector_store\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "OPENAI_API_KEY = os.environ['OPENAI_API_KEY'] or getpass(\"Enter your OpenAI API key: \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "QDRANT_URL = os.environ['QDRANT_URL'] or getpass(\"Enter your Qdrant URL:\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "QDRANT_API_KEY = os.environ['QDRANT_API_KEY'] or  getpass(\"Enter your Qdrant API Key:\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.settings import Settings\n",
    "from llama_index.llms.openai import OpenAI\n",
    "from utils import setup_llm, setup_embed_model\n",
    "\n",
    "setup_llm(\n",
    "    provider=\"openai\", \n",
    "    model=\"gpt-4o\", \n",
    "    api_key=OPENAI_API_KEY\n",
    "    )\n",
    "\n",
    "setup_embed_model(\n",
    "    provider=\"openai\", \n",
    "    model=\"text-embedding-3-small\",\n",
    "    api_key=OPENAI_API_KEY\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from llama_index.core.storage.docstore import SimpleDocumentStore\n",
    "from utils import get_documents_from_docstore, group_documents_by_author, sample_documents\n",
    "\n",
    "documents = get_documents_from_docstore(\"../data/words-of-the-senpais\")\n",
    "\n",
    "random.seed(42)\n",
    "\n",
    "documents_by_author = group_documents_by_author(documents)\n",
    "\n",
    "senpai_documents = sample_documents(documents_by_author, num_samples=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "smol_senpai_docstore = SimpleDocumentStore()\n",
    "smol_senpai_docstore.add_documents(senpai_documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup Qdrant Vector Store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import StorageContext\n",
    "from llama_index.core.storage.docstore import SimpleDocumentStore\n",
    "from llama_index.core.storage.index_store.simple_index_store import SimpleIndexStore\n",
    "from llama_index.core.settings import Settings\n",
    "from utils import setup_vector_store\n",
    "\n",
    "COLLECTION_NAME = \"rr-fusion\"\n",
    "\n",
    "rr_fusion_vector_store = setup_vector_store(\n",
    "    QDRANT_URL, \n",
    "    QDRANT_API_KEY, \n",
    "    COLLECTION_NAME, \n",
    "    enable_hybrid=True\n",
    "    )\n",
    "\n",
    "rr_fusion_storage_context = StorageContext.from_defaults(\n",
    "    docstore = smol_senpai_docstore,\n",
    "    index_store=SimpleIndexStore(),\n",
    "    vector_store = rr_fusion_vector_store\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ingest with a docstore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import VectorStoreIndex\n",
    "from llama_index.core.node_parser import SentenceSplitter\n",
    "from llama_index.core.storage.docstore import SimpleDocumentStore\n",
    "\n",
    "from utils import ingest \n",
    "\n",
    "sentence_splitter = SentenceSplitter(chunk_size=256, chunk_overlap=16)\n",
    "\n",
    "index = VectorStoreIndex.from_documents(\n",
    "    documents=senpai_documents, \n",
    "    embed_model=Settings.embed_model,\n",
    "    storage_context=rr_fusion_storage_context,\n",
    "    transformations=[sentence_splitter, Settings.embed_model]\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A brief word on vector store query modes\n",
    "\n",
    "The `vector_store_query_mode` in LlamaIndex determines the type of search to be performed. Here's a brief description of each mode:\n",
    "\n",
    " - `default`: This mode performs a vector search. It retrieves the most similar vectors based on the query vector.  They create a numerical representation of a piece of text, represented as a long list of numbers. These dense vectors can capture rich semantics across the entire piece of text. `alpha=0.75` is used by default.\n",
    "\n",
    " - `hybrid`: This mode performs a hybrid search. It combines vector search with traditional search methods. `alpha` parameter determines weighting (`alpha = 0` -> bm25, `alpha = 1` -> vector search). \n",
    "\n",
    " - `semantic_hybrid`: Semantic hybrid search combines text search with vector embeddings. Text search provides keyword matching and lexical retrieval. Vector embeddings allow finding documents with similar meaning, even if they don't contain exact keyword matches. This mode incorporates semantic reranking to hybrid search results to improve search relevance.\n",
    "\n",
    " - `sparse`: Most of the elements in a sparse vector are zero, with only a few key values being non-zero. These sparse vectors are great at capturing specific keywords and similar small details. You need to use a specialized embedding model to create sparse vectors. \n",
    "   - `FastEmbed` has a few choices for sparse text embedding models, for example you can pass in `prithvida/Splade_PP_en_v1` as the model name when you run `setup_embed_model` if you want to use them. \n",
    "    - We didn't use a sparse vector here, so we won't see this in action.  \n",
    "    - Note, if you try this you'll need to set the `sparse_top_k` argument, which represents how many nodes will be retrieved from each dense and sparse query. For example, if `sparse_top_k=5` is set, that means I will retrieve 5 nodes using sparse vectors and 5 nodes using dense vectors.\n",
    "\n",
    " - `text_search`: Text search looks for exact keyword matches between the query and documents.\n",
    "\n",
    " - `similarity_top_k`: controls the final number of returned nodes. A fusion algorithm is applied to rank and order the nodes from different vector spaces, `similarity_top_k=2` means the top two nodes after fusion are returned.\n",
    "\n",
    " - `hybrid_top_k`: return top k results from `hybrid` search. `similarity_top_k` is used for dense search top k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieving nodes using: default retrieval\n",
      "Retrieved 3 nodes.\n",
      "\n",
      "\n",
      "Score: 0.37 - became extremely successful. You just had to give them a long enough timescale. It never happens in the timescale you want, or they want, but it does happen. Apply specific knowledge with leverage and eventually, you will get what you deserve. It takes timeeven once you have all of these pieces in place, there is an indeterminate amount of time you have to put in. If youre counting, youll run out of patience before success actually arrives. Everybody wants to get rich immediately, but the world is an efficient place; immediate doesnt work. You do have to put in the time. You do have to put in the hours, and so I think you have to put yourself in the position with the specific knowledge, with accountability, with leverage, with the authentic skill set you have, to be the best in the world at what you do. You have to enjoy it and keep doing it, keep doing it, and keep doing it....\n",
      "-----\n",
      "\n",
      "Score: 0.37 - TIME ACTIONS RESULTS CHOOSING TO GROW YOURSELF I dont believe in specific goals. Scott Adams famously said, Set up systems, not goals. Use your judgment to figure out what kinds of environments you can thrive in, and then create an environment around you so youre statistically likely to succeed. The current environment programs the brain, but the clever brain can choose its upcoming environment. Im not going to be the most successful person on the planet, nor do I want to be. I just want to be the most successful version of myself while working the least hard possible. I want to live in a way that if my life played out 1,000 times, Naval is successful 999 times. Hes not a billionaire, but he does pretty well each time. He may not have nailed life in every regard, but he sets up systems so hes failed in very few places....\n",
      "-----\n",
      "\n",
      "Score: 0.37 - Now, the problem is becoming good at whatever it is. It moves around from generation to generation, but a lot of it happens to be in technology. You are waiting for your moment when something emerges in the world, they need a skill set, and youre uniquely qualified. You build your brand in the meantime on Twitter, on YouTube, and by giving away free work. You make a name for yourself, and you take some risk in the process. When it is time to move...\n",
      "-----\n",
      "\n",
      "Retrieval with default complete...\n",
      "\n",
      "\n",
      "Retrieving nodes using: bm25 retrieval\n",
      "Retrieved 2 nodes.\n",
      "\n",
      "\n",
      "Score: 0.50 - became extremely successful. You just had to give them a long enough timescale. It never happens in the timescale you want, or they want, but it does happen. Apply specific knowledge with leverage and eventually, you will get what you deserve. It takes timeeven once you have all of these pieces in place, there is an indeterminate amount of time you have to put in. If youre counting, youll run out of patience before success actually arrives. Everybody wants to get rich immediately, but the world is an efficient place; immediate doesnt work. You do have to put in the time. You do have to put in the hours, and so I think you have to put yourself in the position with the specific knowledge, with accountability, with leverage, with the authentic skill set you have, to be the best in the world at what you do. You have to enjoy it and keep doing it, keep doing it, and keep doing it....\n",
      "-----\n",
      "\n",
      "Score: 0.50 - Leonardo da Vinci, study of a rearing horse, 1481-99. Now that we have enough computer power, we can imitate natures method as well as its results. Genetic algorithms may let us create things too complex to design in the ordinary sense. Good design is redesign. Its rare to get things right the rst time. Experts expect to throw away some early work. They plan for plans to change. It takes condence to throw work away. You have to be able to think, theres more where that came from. When people rst start drawing, for example, theyre often reluctant to redo parts that arent right. They feel theyve been lucky to get that far, and if they try to redo something, it will turn out worse. Instead they convince themselves that the drawing is not that bad, reallyin fact, maybe they meant it to look that way....\n",
      "-----\n",
      "\n",
      "Retrieval with bm25 complete...\n",
      "\n",
      "\n",
      "Retrieving nodes using: hybrid retrieval\n",
      "Retrieved 2 nodes.\n",
      "\n",
      "\n",
      "Score: 0.75 - Leonardo da Vinci, study of a rearing horse, 1481-99. Now that we have enough computer power, we can imitate natures method as well as its results. Genetic algorithms may let us create things too complex to design in the ordinary sense. Good design is redesign. Its rare to get things right the rst time. Experts expect to throw away some early work. They plan for plans to change. It takes condence to throw work away. You have to be able to think, theres more where that came from. When people rst start drawing, for example, theyre often reluctant to redo parts that arent right. They feel theyve been lucky to get that far, and if they try to redo something, it will turn out worse. Instead they convince themselves that the drawing is not that bad, reallyin fact, maybe they meant it to look that way....\n",
      "-----\n",
      "\n",
      "Score: 0.25 - became extremely successful. You just had to give them a long enough timescale. It never happens in the timescale you want, or they want, but it does happen. Apply specific knowledge with leverage and eventually, you will get what you deserve. It takes timeeven once you have all of these pieces in place, there is an indeterminate amount of time you have to put in. If youre counting, youll run out of patience before success actually arrives. Everybody wants to get rich immediately, but the world is an efficient place; immediate doesnt work. You do have to put in the time. You do have to put in the hours, and so I think you have to put yourself in the position with the specific knowledge, with accountability, with leverage, with the authentic skill set you have, to be the best in the world at what you do. You have to enjoy it and keep doing it, keep doing it, and keep doing it....\n",
      "-----\n",
      "\n",
      "Retrieval with hybrid complete...\n",
      "\n",
      "\n",
      "Retrieving nodes using: semantic_hybrid retrieval\n",
      "Retrieved 2 nodes.\n",
      "\n",
      "\n",
      "Score: 0.37 - became extremely successful. You just had to give them a long enough timescale. It never happens in the timescale you want, or they want, but it does happen. Apply specific knowledge with leverage and eventually, you will get what you deserve. It takes timeeven once you have all of these pieces in place, there is an indeterminate amount of time you have to put in. If youre counting, youll run out of patience before success actually arrives. Everybody wants to get rich immediately, but the world is an efficient place; immediate doesnt work. You do have to put in the time. You do have to put in the hours, and so I think you have to put yourself in the position with the specific knowledge, with accountability, with leverage, with the authentic skill set you have, to be the best in the world at what you do. You have to enjoy it and keep doing it, keep doing it, and keep doing it....\n",
      "-----\n",
      "\n",
      "Score: 0.37 - TIME ACTIONS RESULTS CHOOSING TO GROW YOURSELF I dont believe in specific goals. Scott Adams famously said, Set up systems, not goals. Use your judgment to figure out what kinds of environments you can thrive in, and then create an environment around you so youre statistically likely to succeed. The current environment programs the brain, but the clever brain can choose its upcoming environment. Im not going to be the most successful person on the planet, nor do I want to be. I just want to be the most successful version of myself while working the least hard possible. I want to live in a way that if my life played out 1,000 times, Naval is successful 999 times. Hes not a billionaire, but he does pretty well each time. He may not have nailed life in every regard, but he sets up systems so hes failed in very few places....\n",
      "-----\n",
      "\n",
      "Retrieval with semantic_hybrid complete...\n",
      "\n",
      "\n",
      "Retrieving nodes using: text_search retrieval\n",
      "Retrieved 3 nodes.\n",
      "\n",
      "\n",
      "Score: 0.37 - became extremely successful. You just had to give them a long enough timescale. It never happens in the timescale you want, or they want, but it does happen. Apply specific knowledge with leverage and eventually, you will get what you deserve. It takes timeeven once you have all of these pieces in place, there is an indeterminate amount of time you have to put in. If youre counting, youll run out of patience before success actually arrives. Everybody wants to get rich immediately, but the world is an efficient place; immediate doesnt work. You do have to put in the time. You do have to put in the hours, and so I think you have to put yourself in the position with the specific knowledge, with accountability, with leverage, with the authentic skill set you have, to be the best in the world at what you do. You have to enjoy it and keep doing it, keep doing it, and keep doing it....\n",
      "-----\n",
      "\n",
      "Score: 0.37 - TIME ACTIONS RESULTS CHOOSING TO GROW YOURSELF I dont believe in specific goals. Scott Adams famously said, Set up systems, not goals. Use your judgment to figure out what kinds of environments you can thrive in, and then create an environment around you so youre statistically likely to succeed. The current environment programs the brain, but the clever brain can choose its upcoming environment. Im not going to be the most successful person on the planet, nor do I want to be. I just want to be the most successful version of myself while working the least hard possible. I want to live in a way that if my life played out 1,000 times, Naval is successful 999 times. Hes not a billionaire, but he does pretty well each time. He may not have nailed life in every regard, but he sets up systems so hes failed in very few places....\n",
      "-----\n",
      "\n",
      "Score: 0.37 - Now, the problem is becoming good at whatever it is. It moves around from generation to generation, but a lot of it happens to be in technology. You are waiting for your moment when something emerges in the world, they need a skill set, and youre uniquely qualified. You build your brand in the meantime on Twitter, on YouTube, and by giving away free work. You make a name for yourself, and you take some risk in the process. When it is time to move...\n",
      "-----\n",
      "\n",
      "Retrieval with text_search complete...\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "QUERY_STRING = \"How can I create my own luck?\"\n",
    "\n",
    "def test_retrievers(query=QUERY_STRING, index=index, **kwargs):\n",
    "    retriever_engine = index.as_retriever(**kwargs)\n",
    "    retrieved_docs = retriever_engine.retrieve(query)\n",
    "    print(f\"Retrieved {len(retrieved_docs)} nodes.\")\n",
    "    print(\"\\n\")\n",
    "    for node in retrieved_docs:\n",
    "        print(f\"Score: {node.score:.2f} - {node.text}...\\n-----\\n\")\n",
    "    \n",
    "mode_kwargs = {\n",
    "    'default': {'vector_store_query_mode': 'default', 'similarity_top_k': 3},\n",
    "    'bm25': {'vector_store_query_mode':'hybrid', 'alpha': 0.0, 'hybrid_top_k': 3}, \n",
    "    'hybrid': {'vector_store_query_mode':'hybrid', 'alpha': 0.25, 'hybrid_top_k': 3},\n",
    "    'semantic_hybrid': {'vector_store_query_mode':'semantic_hybrid', 'alpha': 0.75, 'hybrid_top_k': 3},\n",
    "    # 'sparse': {\"sparse_top_k\":5},\n",
    "    'text_search': {'vector_store_query_mode':'text_search', 'similarity_top_k': 3},\n",
    "}\n",
    "\n",
    "for mode, kwargs in mode_kwargs.items():\n",
    "    print(f\"Retrieving nodes using: {mode} retrieval\")\n",
    "    test_retrievers(**kwargs)\n",
    "    print(f\"Retrieval with {mode} complete...\")        \n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hybrid Fusion Retriever\n",
    "\n",
    "The Hybrid Fusion Retriever combines of semantic and keyword-based approaches.  This uses a [BM25-based retriever](https://en.wikipedia.org/wiki/Okapi_BM25) with a semantic index. [BM25](https://github.com/run-llama/llama_index/blob/main/llama-index-integrations/retrievers/llama-index-retrievers-bm25/llama_index/retrievers/bm25/base.py) is a ranking function used by search engines to estimate the relevance of documents to a given search query. \n",
    "\n",
    "#### How it works\n",
    "\n",
    "The system follows a three-step process:\n",
    "\n",
    "- **Query Generation/Rewriting**: It creates multiple queries from the original user query to better match the user's intent and improve the precision and recall of the retrieved results.\n",
    "\n",
    "- **Retrieval**: It performs the retrieval for each query over an ensemble of retrievers.\n",
    "\n",
    "- **Reranking/Fusion**: It combines the results from all queries and applies a reranking step to fuse the top relevant results.\n",
    "\n",
    "#### ‚ÑπÔ∏è Useful knowledge to have as a RAG practitioner\n",
    "\n",
    "##### Index Fusion Mode\n",
    "\n",
    "We set the mode to `reciprocal_rerank`. The system merges its index with a BM25 based retriever. This allows it to understand both the semantic relationships (meaningful connections between words) and keywords in the input queries. Other modes are `relative_score`, `dist_based_score`, `simple` .\n",
    "\n",
    "  - [`reciprocal_rerank`](https://github.com/run-llama/llama_index/blob/f116d75557d6867ed2cc61811a1c2f0b0c4d4ddb/llama-index-core/llama_index/core/retrievers/fusion_retriever.py#L99): Reciprocal rank is a measure of how early a relevant item appears in a ranked list. Lower ranks correspond to higher relevance. This mode fuses the results from multiple sources by giving higher importance to nodes that appear earlier in the rankings across those sources.\n",
    "\n",
    "  - [`relative_score`](https://github.com/run-llama/llama_index/blob/f116d75557d6867ed2cc61811a1c2f0b0c4d4ddb/llama-index-core/llama_index/core/retrievers/fusion_retriever.py#L135): It scales each score to a range from 0 to 1 using min-max scaling. Then it multiplies each scaled score by a retriever-specific weight. After that, it divides each score by the total number of queries. Basically, it scales, weights, and combines scores from multiple retrieval sources.\n",
    "\n",
    "  - `dist_based_score`: Same as `relative_score`, but, instead of using the minimum and maximum scores directly, the function calculates them based on the mean and standard deviation of the scores. This reduces the impact of outliers on the scaling process.\n",
    "\n",
    "  - `simple`: re-orders results based on original scores\n",
    "\n",
    "\n",
    "##### **[Reciprocal Rerank Algorithm](https://plg.uwaterloo.ca/~gvcormac/cormacksigir09-rrf.pdf)**\n",
    "\n",
    " Since both retrievers calculate a score for the relevance of results, the system uses the reciprocal rerank algorithm to reshuffle the results. This is done without employing additional models or excessive computation, making the process more efficient.\n",
    " \n",
    "  - üßÆ **Rank Calculation**: For each unique node, calculate its reciprocal rank from each list where it appears. The reciprocal rank of a node in a list is defined as 1 divided by its position in that list (e.g., a node at rank 3 has a reciprocal rank of 1/3).\n",
    "\n",
    "  - üìä **Score Aggregation**: Sum up the reciprocal ranks for each node across all lists in which it appears. This aggregated score represents the overall relevance of the node, taking into account its performance across multiple retrieval scenarios.\n",
    "\n",
    "  - ü•áü•àü•â **Reordering**: Finally, reorder all nodes based on their aggregated scores, from highest to lowest. This re-ranking step prioritizes nodes that consistently appear in higher ranks across multiple lists, thus likely to be more relevant to the query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.retrievers.bm25 import BM25Retriever\n",
    "from llama_index.core.query_engine import RetrieverQueryEngine\n",
    "from llama_index.core.retrievers import QueryFusionRetriever\n",
    "from llama_index.core import PromptTemplate\n",
    "from prompts import QUESTION_GEN_PROMPT\n",
    "\n",
    "vector_retriever = index.as_retriever(similarity_top_k=1)\n",
    "\n",
    "bm25_retriever = BM25Retriever.from_defaults(docstore=index.docstore, similarity_top_k=1)\n",
    "\n",
    "QUERY_GEN_PROMPT_TEMPLATE=PromptTemplate(QUESTION_GEN_PROMPT)\n",
    "\n",
    "retriever = QueryFusionRetriever(\n",
    "    [vector_retriever, bm25_retriever],\n",
    "    similarity_top_k=15,\n",
    "    num_queries=3,  # set this to 1 to disable query generation\n",
    "    mode=\"reciprocal_rerank\",\n",
    "    use_async=True,\n",
    "    verbose=True,\n",
    "    # query_gen_prompt=QUERY_GEN_PROMPT_TEMPLATE, \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated queries:\n",
      "1. Techniques to stop projecting a facade and embrace authenticity\n",
      "2. Strategies for personal growth and maximizing human potential\n"
     ]
    }
   ],
   "source": [
    "nodes_with_scores = retriever.retrieve(\n",
    "    \"How can I stop wasting energy on projecting a facade and focus on expanding my potential as a human being?\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 0.03 - TIME ACTIONS RESULTS CHOOSING TO GROW YOURSELF I dont believe in specific goals. Scott Adams famously said, Set up systems, not goals. Use your judgment to figure out what kinds of environments you can thrive in, and then create an environment around you so youre statistically likely to succeed. The current environment programs the brain, but the clever brain can choose its upcoming environment. Im not going to be the most successful person on the planet, nor do I want to be. I just want to be the most successful version of myself while working the least hard possible. I want to live in a way that if my life played out 1,000 times, Naval is successful 999 times. Hes not a billionaire, but he does pretty well each time. He may not have nailed life in every regard, but he sets up systems so hes failed in very few places....\n",
      "-----\n",
      "\n",
      "Score: 0.02 - Motivation Your mind determines the effect. - Everyone - no matter who he is or where - must know from childhood that whatever occurs, does not happen if the occurrence isn't allowed to come into the mind. It is not what happens in our life that is important, it's how we react to what happens. Failure is what your mind acknowledges. Suffering is mostly self-manufactured. -Joy and suffering are the fruit of right and wrong thinking. Suffering, especially, is mostly self-manufactured; we are never so happy or so unhappy as we suppose. To go one step beyond, according to Taosim, suffering and joy are one! Defeat is a state of mind. - Defeat is a state of mind; no one is ever defeated until defeat has been accepted as a reality. Defeat is temporary. -To me, defeat in anything is merely temporary, and its punishment is but an urge for me to greater effort to achieve my goal. Defeat simply tells me that something is wrong in my doing; it is a path leading to success and truth. Dont choose to waste energy. -Never waste energy on worries or negative thoughts. All problems are brought into existence - drop them. To be discouraged is to be defeated. - It is not what happens that is success or failure, but what it does to the heart of man. No man is defeated unless he is discouraged....\n",
      "-----\n",
      "\n",
      "Score: 0.02 - somebody. Anyone around whom I cant be fully honest, I dont want to be around. Before you can lie to another, you must first lie to yourself. Another example of a foundational value: I dont believe in any short-term thinking or dealing. If Im doing business with somebody and they think in a short-term manner with somebody else, then I dont want to do business with them anymore. All benefits in life come from compound interest, whether in money, relationships, love, health, activities, or habits. I only want to be around people I know Im going to be around for the rest of my life. I only want to work on things I know have long-term payout. Another one is I only believe in peer relationships. I dont believe in hierarchical relationships. I dont want to be above anybody, and I dont want to be below anybody. If I cant treat someone like a peer and if they cant treat me like peer, I just dont want to interact with them....\n",
      "-----\n",
      "\n",
      "Score: 0.02 - it. Engineers will work on sexy projects like ghter planes and moon rockets for ordinary salaries, but more mundane technologies like light bulbs or semiconductors have to be developed by entrepreneurs. Startups are not just something that happened in Silicon Valley in the last couple decades. Since it became possible to get rich by creating wealth, everyone who has done it has used essentially the same recipe: measurement and leverage, where measurement comes from working with a small group, and leverage from developing new techniques. The recipe was the same in Florence in 1200 as it is in Santa Clara today. Understanding this may help to answer an important question: why Europe grew so powerful. Was it something about the geography of Europe? Was it that Europeans are somehow racially superior? Was it their religion? The answer (or at least the proximate cause) may be that the Europeans rode on the crest of a powerful new idea: allowing those who made a lot of money to keep it. Once youre allowed to do that, people who want to get rich can do it by generating wealth instead of stealing it. The resulting technological growth translates not only into wealth but into military power. The theory that led to the stealth plane was developed by a Soviet mathematician. But because the Soviet Union didnt have a computer industry, it remained for them a theory; they didnt have hardware capable of executing the calculations fast enough to design an actual airplane. In that respect the Cold War teaches the same lesson as World War II and, for that matter, most wars in recent history. Dont let a ruling class of warriors and politicians squash the entrepreneurs. The same recipe that makes individuals rich makes countries powerful. Let the nerds keep their lunch money, and you rule the world....\n",
      "-----\n",
      "\n",
      "Score: 0.02 - unconditional love for me. She treats our relationship with calmness [and] objectivity, and without conditions. I think this is the kind of attitude that a couple should adopt. For example, if I state a point, my wife will express her ideas on it. Certainly we ought to discuss things or it would be difficult for us to get along well. The importance of acknowledging your love. - A very important person I like to thank. A quality human being in her own right-giving, loving, stalwart, understanding this animal, Bruce Lee. And letting him simply be. My companion in our separate but intertwined pathways of growth, a definite enricher of my life, the woman I love; and - fortunately for me - my wife. I cannot leave this paragraph without saying that Linda, thanks for the day when, at the University of Washington, Bruce Lee had the honor to meet you....\n",
      "-----\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for node in nodes_with_scores:\n",
    "    print(f\"Score: {node.score:.2f} - {node.text}...\\n-----\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.response_synthesizers import ResponseMode\n",
    "from llama_index.core.query_pipeline import InputComponent\n",
    "\n",
    "from utils import create_query_pipeline\n",
    "from prompts import HYPE_ANSWER_GEN_PROMPT\n",
    "\n",
    "input_component = InputComponent()\n",
    "\n",
    "HYPE_ANSWER_GEN_PROMPT_TEMPLATE = PromptTemplate(HYPE_ANSWER_GEN_PROMPT)\n",
    "\n",
    "rr_fusion_query_engine = RetrieverQueryEngine.from_args(\n",
    "    retriever,\n",
    "    response_mode = ResponseMode.COMPACT_ACCUMULATE,\n",
    "    use_async = True,\n",
    "    text_qa_template = HYPE_ANSWER_GEN_PROMPT_TEMPLATE\n",
    "    )\n",
    "\n",
    "rr_fusion_chain = [input_component, rr_fusion_query_engine]\n",
    "\n",
    "rr_fusion_query_pipeline = create_query_pipeline(rr_fusion_chain)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lil_llama_index",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
